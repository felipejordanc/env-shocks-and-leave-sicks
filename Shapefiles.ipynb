{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad3066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Centroides_Manzana_32718.shp\n",
      "Exportado: C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Centroides_Manzana_32719.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "input_path = r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Microdatos_Manzana.shp\"\n",
    "out_dir = Path(r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load\n",
    "gdf = gpd.read_file(input_path)\n",
    "\n",
    "# Regiones para EPSG 32718\n",
    "regiones_epsg32718 = [\n",
    "    \"REGIÓN DE ATACAMA\",\n",
    "    \"REGIÓN DE ARICA Y PARINACOTA\",\n",
    "    \"REGIÓN DE COQUIMBO\",\n",
    "    \"REGIÓN DE VALPARAÍSO\",\n",
    "    \"REGIÓN DE TARAPACÁ\",\n",
    "    \"REGIÓN DE ANTOFAGASTA\"\n",
    "]\n",
    "\n",
    "# Calcular centroides\n",
    "gdf[\"geometry\"] = gdf.geometry.centroid\n",
    "\n",
    "# Dividir y reproyectar\n",
    "gdf_18 = gdf[gdf[\"REGION\"].isin(regiones_epsg32718)].to_crs(epsg=32718)[[\"CUT\", \"TOTAL_PERS\", \"geometry\"]]\n",
    "gdf_19 = gdf[~gdf[\"REGION\"].isin(regiones_epsg32718)].to_crs(epsg=32719)[[\"CUT\", \"TOTAL_PERS\", \"geometry\"]]\n",
    "\n",
    "# Guardar shapefiles separados\n",
    "out18 = out_dir / \"Centroides_Manzana_32718.shp\"\n",
    "out19 = out_dir / \"Centroides_Manzana_32719.shp\"\n",
    "\n",
    "gdf_18.to_file(out18, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "gdf_19.to_file(out19, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Exportado: {out18}\")\n",
    "print(f\"Exportado: {out19}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce14a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_24588\\1824467658.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Entidad_Promedios_32718.shp\n",
      "Exportado: C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Entidad_Promedios_32719.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "poly_path = r\"C:\\Users\\black\\Downloads\\microdatos_entidad\\Microdatos_Entidad.shp\"\n",
    "points_path = r\"C:\\Users\\black\\Downloads\\viviendas-rurales-precenso-2016\\Viviendas_Rurales_Precenso_2016.shp\"\n",
    "out_dir = Path(r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Leer shapefiles ===\n",
    "polys = gpd.read_file(poly_path)\n",
    "pts = gpd.read_file(points_path)\n",
    "\n",
    "# === Regiones EPSG 32718 ===\n",
    "regiones_32718 = [1, 2, 3, 4, 5, 15]\n",
    "\n",
    "# Asegurar que ambos tengan el mismo CRS para hacer spatial join\n",
    "if polys.crs != pts.crs:\n",
    "    pts = pts.to_crs(polys.crs)\n",
    "\n",
    "# === Join espacial: asignar puntos a polígonos ===\n",
    "joined = gpd.sjoin(pts, polys, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# === Calcular promedio de coordenadas por polígono ===\n",
    "means = (\n",
    "    joined.groupby(\"index_right\")\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"x_mean\": g.geometry.x.mean(),\n",
    "        \"y_mean\": g.geometry.y.mean()\n",
    "    }))\n",
    ")\n",
    "\n",
    "# === Unir resultados con atributos de los polígonos ===\n",
    "polys_reset = polys.reset_index()\n",
    "result = polys_reset.merge(means, left_index=True, right_index=True)\n",
    "\n",
    "# Crear geometría con el promedio\n",
    "result[\"geometry\"] = [Point(xy) for xy in zip(result[\"x_mean\"], result[\"y_mean\"])]\n",
    "\n",
    "# Seleccionar columnas necesarias\n",
    "result = result[[\"COD_COMUNA\", \"TOTAL_PERS\", \"COD_REGION\", \"geometry\"]]\n",
    "result = gpd.GeoDataFrame(result, geometry=\"geometry\", crs=polys.crs)\n",
    "\n",
    "# === Separar por EPSG ===\n",
    "gdf_18 = result[result[\"COD_REGION\"].astype(int).isin(regiones_32718)].to_crs(epsg=32718)\n",
    "gdf_19 = result[~result[\"COD_REGION\"].astype(int).isin(regiones_32718)].to_crs(epsg=32719)\n",
    "\n",
    "# === Guardar ===\n",
    "out18 = out_dir / \"Entidad_Promedios_32718.shp\"\n",
    "out19 = out_dir / \"Entidad_Promedios_32719.shp\"\n",
    "\n",
    "gdf_18.to_file(out18, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "gdf_19.to_file(out19, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Exportado: {out18}\")\n",
    "print(f\"Exportado: {out19}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b05a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\n",
      "Exportado: C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_22568\\1534637724.py:40: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf_18.to_file(out18, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_22568\\1534637724.py:44: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf_19.to_file(out19, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "excel_path = r\"C:\\Users\\black\\Documents\\SINCA\\stations_info_stata.xlsx\"\n",
    "out_dir = Path(r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Leer Excel ===\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Eliminar duplicados por Estación\n",
    "df = df.drop_duplicates(subset=[\"Estación\"])\n",
    "\n",
    "# Crear geometría desde Lat / Lon (en WGS84)\n",
    "geometry = [Point(xy) for xy in zip(df[\"Longitud\"], df[\"Latitud\"])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Regiones que van con EPSG 32718\n",
    "regiones_32718 = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"XV\"]\n",
    "\n",
    "# Dividir según región y transformar CRS\n",
    "gdf_18 = gdf[gdf[\"Regióncódigo\"].isin(regiones_32718)].to_crs(epsg=32718)\n",
    "gdf_19 = gdf[~gdf[\"Regióncódigo\"].isin(regiones_32718)].to_crs(epsg=32719)\n",
    "\n",
    "# Convertir fechas a string (si existen)\n",
    "for col in [\"date_inicio\", \"date_fin\"]:\n",
    "    if col in gdf_18.columns:\n",
    "        gdf_18[col] = gdf_18[col].astype(str)\n",
    "    if col in gdf_19.columns:\n",
    "        gdf_19[col] = gdf_19[col].astype(str)\n",
    "\n",
    "# === Exportar ===\n",
    "out18 = out_dir / \"Coordenadas_LatLon_32718.shp\"\n",
    "out19 = out_dir / \"Coordenadas_LatLon_32719.shp\"\n",
    "\n",
    "if not gdf_18.empty:\n",
    "    gdf_18.to_file(out18, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "    print(f\"Exportado: {out18}\")\n",
    "\n",
    "if not gdf_19.empty:\n",
    "    gdf_19.to_file(out19, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "    print(f\"Exportado: {out19}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b4937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import nearest_points\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_df(entidades_path, centros_path, csv_path, radius_km=2):\n",
    "    # Load shapefiles\n",
    "    entidades = gpd.read_file(entidades_path)\n",
    "    centros = gpd.read_file(centros_path)\n",
    "\n",
    "    # Load allowed Estaciones from CSV\n",
    "    valid_estaciones = pd.read_csv(csv_path)[\"Estación\"].astype(str).unique()\n",
    "\n",
    "    # Keep only matching centros\n",
    "    centros = centros[centros[\"Estación\"].astype(str).isin(valid_estaciones)].copy()\n",
    "\n",
    "    # Project to metric CRS\n",
    "    entidades = entidades.to_crs(epsg=32719)  # Adjust CRS if needed\n",
    "    centros = centros.to_crs(entidades.crs)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for idx, ent in entidades.iterrows():\n",
    "        ent_geom = ent.geometry\n",
    "\n",
    "        # Compute distances\n",
    "        centros[\"dist_m\"] = centros.geometry.distance(ent_geom)\n",
    "        nearby = centros[centros[\"dist_m\"] <= radius_km * 1000].copy()\n",
    "\n",
    "        if nearby.empty:\n",
    "            records.append({\n",
    "                \"Entidad\": ent.get(\"name\", idx),  # adjust col name\n",
    "                \"Estación\": \".\",\n",
    "                \"cod_comuna\": ent[\"CUT\"],\n",
    "                \"weight\": 0\n",
    "            })\n",
    "        else:\n",
    "            # Inverse distance weights\n",
    "            nearby[\"inv_dist\"] = 1 / nearby[\"dist_m\"]\n",
    "            nearby[\"weight\"] = nearby[\"inv_dist\"] / nearby[\"inv_dist\"].sum()\n",
    "\n",
    "            for _, cen in nearby.iterrows():\n",
    "                records.append({\n",
    "                    \"Entidad\": ent.get(\"name\", idx),\n",
    "                    \"Estación\": cen[\"Estación\"],\n",
    "                    \"cod_comuna\": ent[\"CUT\"],  # keep original name\n",
    "                    \"weight\": cen[\"weight\"]\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def build_df2(entidades_path, centros_path, csv_path, radius_km=2):\n",
    "    # Load shapefiles\n",
    "    entidades = gpd.read_file(entidades_path)\n",
    "    centros = gpd.read_file(centros_path)\n",
    "\n",
    "    # Load allowed Estaciones from CSV\n",
    "    valid_estaciones = pd.read_csv(csv_path)[\"Estación\"].astype(str).unique()\n",
    "\n",
    "    # Keep only matching centros\n",
    "    centros = centros[centros[\"Estación\"].astype(str).isin(valid_estaciones)].copy()\n",
    "\n",
    "    # Project to metric CRS\n",
    "    entidades = entidades.to_crs(epsg=32719)  # Adjust CRS if needed\n",
    "    centros = centros.to_crs(entidades.crs)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for idx, ent in entidades.iterrows():\n",
    "        ent_geom = ent.geometry\n",
    "\n",
    "        # Compute distances\n",
    "        centros[\"dist_m\"] = centros.geometry.distance(ent_geom)\n",
    "        nearby = centros[centros[\"dist_m\"] <= radius_km * 1000].copy()\n",
    "\n",
    "        if nearby.empty:\n",
    "            records.append({\n",
    "                \"Entidad\": ent.get(\"name\", idx),  # adjust col name\n",
    "                \"Estación\": \".\",\n",
    "                \"cod_comuna\": ent[\"COD_COMUNA\"],\n",
    "                \"weight\": 0\n",
    "            })\n",
    "        else:\n",
    "            # Inverse distance weights\n",
    "            nearby[\"inv_dist\"] = 1 / nearby[\"dist_m\"]\n",
    "            nearby[\"weight\"] = nearby[\"inv_dist\"] / nearby[\"inv_dist\"].sum()\n",
    "\n",
    "            for _, cen in nearby.iterrows():\n",
    "                records.append({\n",
    "                    \"Entidad\": ent.get(\"name\", idx),\n",
    "                    \"Estación\": cen[\"Estación\"],\n",
    "                    \"cod_comuna\": ent[\"COD_COMUNA\"],  # keep original name\n",
    "                    \"weight\": cen[\"weight\"]\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# ---- USAGE ----\n",
    "df1 = build_df(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Centroides_Manzana_32718.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=2)\n",
    "df2 = build_df(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Centroides_Manzana_32719.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=2)\n",
    "df3 = build_df2(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Entidad_Promedios_32718.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=2)\n",
    "df4 = build_df2(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Entidad_Promedios_32719.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=2)\n",
    "# Append both results\n",
    "df1[\"shp\"] = 1\n",
    "df2[\"shp\"] = 2\n",
    "df3[\"shp\"] = 3\n",
    "df4[\"shp\"] = 4\n",
    "final_df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# Export to Excel\n",
    "final_df.to_excel(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\entidades_centros.xlsx\", index=False)\n",
    "# ---- USAGE ----\n",
    "df21 = build_df(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Centroides_Manzana_32718.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=5)\n",
    "df22 = build_df(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Centroides_Manzana_32719.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=5)\n",
    "df23 = build_df2(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Entidad_Promedios_32718.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=5)\n",
    "df24 = build_df2(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Entidad_Promedios_32719.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=5)\n",
    "# Append both results\n",
    "df21[\"shp\"] = 1\n",
    "df22[\"shp\"] = 2\n",
    "df23[\"shp\"] = 3\n",
    "df24[\"shp\"] = 4\n",
    "final_df2 = pd.concat([df21, df22, df23, df24], ignore_index=True)\n",
    "\n",
    "# Export to Excel\n",
    "final_df2.to_excel(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\entidades_centros2.xlsx\", index=False)\n",
    "# ---- USAGE ----\n",
    "df31 = build_df(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Centroides_Manzana_32718.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=10)\n",
    "df32 = build_df(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Centroides_Manzana_32719.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=10)\n",
    "df33 = build_df2(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Entidad_Promedios_32718.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32718.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=10)\n",
    "df34 = build_df2(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\Entidad_Promedios_32719.shp\", r\"C:\\Users\\black\\Downloads\\microdatos_manzana\\Centroide\\Coordenadas_LatLon_32719.shp\", r\"C:\\Users\\black\\Documents\\SINCA\\centros.csv\", radius_km=10)\n",
    "# Append both results\n",
    "df31[\"shp\"] = 1\n",
    "df32[\"shp\"] = 2\n",
    "df33[\"shp\"] = 3\n",
    "df34[\"shp\"] = 4\n",
    "final_df3 = pd.concat([df31, df32, df33, df34], ignore_index=True)\n",
    "\n",
    "# Export to Excel\n",
    "final_df3.to_excel(r\"C:\\Users\\black\\Dropbox\\Proyectos\\microdatos_manzana\\Centroide\\entidades_centros3.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
