# --- Libraries ---
library(haven)
library(dplyr)
library(ggplot2)

# --- Input and Output Paths ---
base_path <- "C:/Users/black/Dropbox/Sick Leave, Heat, Pollution/data/B_intermediate/"
out_path  <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/graphs/"

# --- Files to process ---
files <- list(
  tmax = paste0(base_path, "climate_tmax.dta"),
  tmin = paste0(base_path, "climate_tmin.dta"),
  pr   = paste0(base_path, "climate_pr.dta")
)

# --- Function to process and plot each dataset ---
process_climate <- function(file_path, var_name) {
  message(paste("Processing:", var_name))

  # --- STEP 1: Read and prepare data ---
  data <- read_dta(file_path)
  data$year <- format(data$date, "%Y")

  # Average by comuna-year
  df_s <- data %>%
    group_by(cod_comuna, year) %>%
    summarise(tempe = mean(value, na.rm = TRUE), .groups = "drop")

  # --- STEP 2: Normalize each comuna (baseline = 100) ---
  df <- df_s %>%
    group_by(cod_comuna) %>%
    arrange(year, .by_group = TRUE) %>%
    mutate(
      baseline = first(tempe),
      temp = 100 * tempe / baseline
    ) %>%
    ungroup()
  # --- STEP 4: Compute cumulative/consistent growth per comuna ---
  growth_summary <- df %>%
    group_by(cod_comuna) %>%
    summarise(
      cum_growth = mean(temp - 100, na.rm = TRUE),  # average % above baseline
      .groups = "drop"
    )
  # --- STEP 5.1: Trim outliers (5–95 percentile) ---
  p5  <- quantile(growth_summary$cum_growth, 0.05, na.rm = TRUE)
  p95 <- quantile(growth_summary$cum_growth, 0.95, na.rm = TRUE)
  growth_summary <- growth_summary %>%
    filter(cum_growth >= p5, cum_growth <= p95)
    
    # Filter the main df to keep only trimmed comunas
  df <- df %>%
    filter(cod_comuna %in% growth_summary$cod_comuna)
  # --- STEP 3: Compute yearly mean across comunas (cod_comuna = 20000) ---
  df_mean <- df %>%
    group_by(year) %>%
    summarise(
      temp = mean(temp, na.rm = TRUE),
      cod_comuna = 20000
    )



  # Identify key comunas
  most_growth_id   <- growth_summary$cod_comuna[which.max(growth_summary$cum_growth)]
  least_growth_id  <- growth_summary$cod_comuna[which.min(growth_summary$cum_growth)]
  mean_growth_val  <- mean(growth_summary$cum_growth, na.rm = TRUE)
  closest_mean_id  <- growth_summary$cod_comuna[which.min(abs(growth_summary$cum_growth - mean_growth_val))]

  # --- STEP 5: Create labeled versions for plotting ---
  df_most  <- df %>% filter(cod_comuna == most_growth_id)  %>% mutate(cod_comuna = 30001)
  df_least <- df %>% filter(cod_comuna == least_growth_id) %>% mutate(cod_comuna = 30002)
  df_mid   <- df %>% filter(cod_comuna == closest_mean_id) %>% mutate(cod_comuna = 30003)

  # Combine all data
  df_final <- bind_rows(df, df_mean, df_most, df_least, df_mid)

  # --- STEP 6: Plot ---
  p <- ggplot(df_final, aes(x = as.numeric(year), y = temp, group = cod_comuna)) +
    # Background lines
    geom_line(aes(color = "Other comunas"), alpha = 0.2, linewidth = 0.3, show.legend = FALSE) +

    # Highlight Mean
    geom_line(
      data = subset(df_final, cod_comuna == 20000),
      aes(color = "Mean"),
      linewidth = 1
    ) +
    # Highlight Most Growth
    geom_line(
      data = subset(df_final, cod_comuna == 30001),
      aes(color = "Highest growth"),
      linewidth = 1
    ) +
    # Highlight Least Growth
    geom_line(
      data = subset(df_final, cod_comuna == 30002),
      aes(color = "Lowest growth"),
      linewidth = 1
    ) +
    # Highlight Closest to Mean
    geom_line(
      data = subset(df_final, cod_comuna == 30003),
      aes(color = "Closest to mean"),
      linewidth = 1
    ) +

    # Manual color and legend labels
    scale_color_manual(values = c(
      "Other comunas" = "gray60",
      "Mean" = "black",
      "Highest growth" = "red",
      "Lowest growth" = "green",
      "Closest to mean" = "blue"
    )) +

    # Titles and labels
    labs(
      x = "Year",
      y = "Climate Index (baseline = 100)",
      color = "Comuna type",
      title = paste("Climate Trends by Comuna -", toupper(var_name)),
      subtitle = paste0(
        "Highlighted automatically:\n",
        "Highest growth: ", most_growth_id, " | ",
        "Lowest growth: ", least_growth_id, " | ",
        "Closest to mean: ", closest_mean_id
      )
    ) +
    theme_minimal()

  # --- STEP 7: Export data and plot ---
  ggsave(
    filename = paste0(out_path, "plot_", var_name, ".png"),
    plot = p,
    width = 8,
    height = 5,
    dpi = 300
  )

  message(paste("✅ Done:", var_name))
  return(list(data = df_final, plot = p))
}

# --- STEP 8: Run loop for all variables ---
results <- lapply(names(files), function(nm) process_climate(files[[nm]], nm))
names(results) <- names(files)



# --- Input and Output Paths ---
base_path <- "C:/Users/black/Dropbox/Sick Leave, Heat, Pollution/data/B_intermediate/"
out_path  <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/graphs/"

# --- STEP 1: Load one dataset containing all variables ---
data <- read_dta(paste0(base_path, "pollution.dta"))

# Expect structure like: cod_comuna, date, tmax, tmin, pr
data$year <- format(data$date, "%Y")

# --- Variables to process ---
vars <- c("meanMP10", "meanMP25", "meanNOX", "meanO3")

# --- Function to process and plot each variable ---
process_var <- function(df, var_name) {
  message(paste("Processing:", var_name))
  
  # --- STEP 2: Average by comuna-year for that variable ---
  df_s <- df %>%
    group_by(cod_comuna, year) %>%
    summarise(
      tempe = mean(.data[[var_name]], na.rm = TRUE),
      .groups = "drop"
    )

  # --- STEP 3: Normalize (baseline = 100) ---
  df_norm <- df_s %>%
    group_by(cod_comuna) %>%
    arrange(year, .by_group = TRUE) %>%
    mutate(
      baseline = first(tempe),
      temp = 100 * tempe / baseline
    ) %>%
    ungroup()
  # --- STEP 5: Consistent (cumulative) growth ---
  growth_summary <- df_norm %>%
    group_by(cod_comuna) %>%
    summarise(
      cum_growth = mean(temp - 100, na.rm = TRUE),
      .groups = "drop"
    )
    # --- STEP 5.1: Trim outliers (5–95 percentile) ---
  p5  <- quantile(growth_summary$cum_growth, 0.05, na.rm = TRUE)
  p95 <- quantile(growth_summary$cum_growth, 0.95, na.rm = TRUE)
  growth_summary <- growth_summary %>%
    filter(cum_growth >= p5, cum_growth <= p95)
  # Filter the main df to keep only trimmed comunas
  df_norm <- df_norm %>%
    filter(cod_comuna %in% growth_summary$cod_comuna)
  # --- STEP 4: Compute yearly mean (cod_comuna = 20000) ---
  df_mean <- df_norm %>%
    group_by(year) %>%
    summarise(
      temp = mean(temp, na.rm = TRUE),
      cod_comuna = 20000
    )



  most_growth_id   <- growth_summary$cod_comuna[which.max(growth_summary$cum_growth)]
  least_growth_id  <- growth_summary$cod_comuna[which.min(growth_summary$cum_growth)]
  mean_growth_val  <- mean(growth_summary$cum_growth, na.rm = TRUE)
  closest_mean_id  <- growth_summary$cod_comuna[which.min(abs(growth_summary$cum_growth - mean_growth_val))]

  # --- STEP 6: Create labeled versions ---
  df_most  <- df_norm %>% filter(cod_comuna == most_growth_id)  %>% mutate(cod_comuna = 30001)
  df_least <- df_norm %>% filter(cod_comuna == least_growth_id) %>% mutate(cod_comuna = 30002)
  df_mid   <- df_norm %>% filter(cod_comuna == closest_mean_id) %>% mutate(cod_comuna = 30003)
  
  df_final <- bind_rows(df_norm, df_mean, df_most, df_least, df_mid)

  # --- STEP 7: Plot ---
  p <- ggplot(df_final, aes(x = as.numeric(year), y = temp, group = cod_comuna)) +
    geom_line(aes(color = "Other comunas"), alpha = 0.2, linewidth = 0.3, show.legend = FALSE) +
    geom_line(data = subset(df_final, cod_comuna == 20000), aes(color = "Mean"), linewidth = 1) +
    geom_line(data = subset(df_final, cod_comuna == 30001), aes(color = "Highest growth"), linewidth = 1) +
    geom_line(data = subset(df_final, cod_comuna == 30002), aes(color = "Lowest growth"), linewidth = 1) +
    geom_line(data = subset(df_final, cod_comuna == 30003), aes(color = "Closest to mean"), linewidth = 1) +
    scale_color_manual(values = c(
      "Other comunas" = "gray60",
      "Mean" = "black",
      "Highest growth" = "red",
      "Lowest growth" = "green",
      "Closest to mean" = "blue"
    )) +
    labs(
      x = "Year",
      y = paste0(toupper(var_name), " Index (baseline = 100)"),
      color = "Comuna type",
      title = paste("Pollution Trends by Comuna -", toupper(var_name)),
      subtitle = paste0(
        "Highlighted automatically:\n",
        "Highest growth: ", most_growth_id, " | ",
        "Lowest growth: ", least_growth_id, " | ",
        "Closest to mean: ", closest_mean_id
      )
    ) +
    theme_minimal()

  # --- STEP 8: Export ---
  ggsave(
    filename = paste0(out_path, "plot_", var_name, ".png"),
    plot = p,
    width = 8, height = 5, dpi = 300
  )

  message(paste("✅ Done:", var_name))
  return(list(data = df_final, plot = p))
}

# --- STEP 9: Loop over variables ---
results <- lapply(vars, function(v) process_var(data, v))
names(results) <- vars

########################################################

# Load required packages
library(tidyverse)

#----------------------------------------------------------
# 1. READ & PARSE .TEX REGRESSION TABLE AUTOMATICALLY
#----------------------------------------------------------

tex_file <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/tables/y_sick_w.tex"   # ← change to your .tex path

raw <- readLines(tex_file)
#----------------------------------------------------------
# 2. EXTRACT COEFFICIENT ROWS (dum\_ pattern)
#----------------------------------------------------------

coef_rows <- raw[str_detect(raw, "dum\\\\_")]

#----------------------------------------------------------
# 3. EXTRACT STANDARD ERROR ROWS
#----------------------------------------------------------

se_rows <- raw[str_detect(raw, "\\([0-9]*\\.?[0-9]+\\)")] 

#----------------------------------------------------------
# 4. MATCH LENGTHS
#----------------------------------------------------------

n_coef <- length(coef_rows)
n_se   <- length(se_rows)

if (n_coef > n_se) {
  coef_rows <- coef_rows[1:n_se]
}

#----------------------------------------------------------
# 5. PARSE COEFFICIENT ROWS
#----------------------------------------------------------

clean_num <- function(x) {
  x |>
    str_replace_all("\\\\sym\\{\\*+\\}", "") |>
    str_squish() |>
    as.numeric()
}

coef_df <- tibble(row = coef_rows) |>
  mutate(
    # bin names; convert "dum\_9" → "dum_9"
    bin = str_extract(row, "dum\\\\_[0-9_]+") |> 
      str_replace_all("\\\\_", "_"),

    coef1 = str_match(row, "&\\s*([^&\\\\]+)")[,2] |> clean_num(),
    coef2 = str_match(row, "&[^&]+&\\s*([^\\\\]+)")[,2] |> clean_num()
  ) |>
  select(bin, coef1, coef2)

#----------------------------------------------------------
# 6. PARSE SE ROWS
#----------------------------------------------------------

se_df <- tibble(row = se_rows) |>
  mutate(
    se1 = str_extract(row, "\\(([0-9\\.]+)\\)") |> 
      str_remove_all("[()]") |> as.numeric(),

    se2 = str_extract(row, "\\)\\s*&\\s*\\(([0-9\\.]+)\\)") |> 
      str_remove_all("[()]") |> as.numeric()
  ) |>
  select(se1, se2)

#----------------------------------------------------------
# 7. COMBINE + COMPUTE CI
#----------------------------------------------------------

reg_df <- bind_cols(coef_df, se_df)

reg_clean <- reg_df |>
  mutate(
    estimate = coef1,
    se = se1,
    lower = estimate - 1.96 * se,
    upper = estimate + 1.96 * se,
    bin = fct_inorder(bin),
    bin_index = row_number()
  ) |>
  select(bin, estimate, se, lower, upper, bin_index)

#----------------------------------------------------------
# 8. PLACE TO RENAME BINS
#----------------------------------------------------------
# Create a named vector:
# NEW_LABELS["old_bin_name"] = "new_label"

NEW_LABELS <- c(
  dum_9 = "< 9",
  dum_10 = "10–11",
  dum_12 = "12–13",
  dum_14 = "14–15",
  dum_16 = "16–17",
  dum_18 = "18–19",
  dum_22 = "22–23",
  dum_24 = "24–25",
  dum_26 = "26–27",
  dum_28 = "28–29",
  dum_30 = "30–31",
  dum_32 = "32–33",
  dum_34 = "34–35",
  dum_36 = "36–37",
  dum_38    = "> 38"
)

# Apply custom labels:
reg_clean <- reg_clean |>
  mutate(bin_label = recode(bin, !!!NEW_LABELS))

#----------------------------------------------------------
# 9. COLOR GRADIENT BASED ON BIN ORDER
#----------------------------------------------------------

my_cols <- scales::seq_gradient_pal(low = "#008080", high = "#CC0000")

#----------------------------------------------------------
# 10. BAR PLOT WITH BLACK ERROR BARS
#----------------------------------------------------------

reg_clean |>
  ggplot(aes(x = fct_inorder(bin_label), 
             y = estimate,
             fill = bin_index)) +
  geom_col(width = 0.8) +
  geom_errorbar(
    aes(ymin = lower, ymax = upper),
    width = 0.15,
    color = "black"
  ) +
  scale_fill_gradientn(
    colors = my_cols(seq(0, 1, length.out = nrow(reg_clean))),
    guide = "none"   # <-- removes legend
  ) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_cartesian(ylim = c(-1, 1)) +
  labs(
    x = "Bin",
    y = "Estimate",
    title = "Regression Coefficients ",
    subtitle = "Max weekly temperature"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 60, hjust = 1)
  )