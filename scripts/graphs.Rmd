# --- Libraries ---
library(haven)
library(dplyr)
library(ggplot2)

# --- Input and Output Paths ---
base_path <- "C:/Users/black/Dropbox/Sick Leave, Heat, Pollution/data/B_intermediate/"
out_path  <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/graphs/"

# --- Files to process ---
files <- list(
  tmax = paste0(base_path, "climate_tmax.dta"),
  tmin = paste0(base_path, "climate_tmin.dta"),
  pr   = paste0(base_path, "climate_pr.dta")
)

# --- Function to process and plot each dataset ---
process_climate <- function(file_path, var_name) {
  message(paste("Processing:", var_name))

  # --- STEP 1: Read and prepare data ---
  data <- read_dta(file_path)
  data$year <- format(data$date, "%Y")

  # Average by comuna-year
  df_s <- data %>%
    group_by(cod_comuna, year) %>%
    summarise(tempe = mean(value, na.rm = TRUE), .groups = "drop")

  # --- STEP 2: Normalize each comuna (baseline = 100) ---
  df <- df_s %>%
    group_by(cod_comuna) %>%
    arrange(year, .by_group = TRUE) %>%
    mutate(
      baseline = first(tempe),
      temp = 100 * tempe / baseline
    ) %>%
    ungroup()
  # --- STEP 4: Compute cumulative/consistent growth per comuna ---
  growth_summary <- df %>%
    group_by(cod_comuna) %>%
    summarise(
      cum_growth = mean(temp - 100, na.rm = TRUE),  # average % above baseline
      .groups = "drop"
    )
  # --- STEP 5.1: Trim outliers (5–95 percentile) ---
  p5  <- quantile(growth_summary$cum_growth, 0.05, na.rm = TRUE)
  p95 <- quantile(growth_summary$cum_growth, 0.95, na.rm = TRUE)
  growth_summary <- growth_summary %>%
    filter(cum_growth >= p5, cum_growth <= p95)
    
    # Filter the main df to keep only trimmed comunas
  df <- df %>%
    filter(cod_comuna %in% growth_summary$cod_comuna)
  # --- STEP 3: Compute yearly mean across comunas (cod_comuna = 20000) ---
  df_mean <- df %>%
    group_by(year) %>%
    summarise(
      temp = mean(temp, na.rm = TRUE),
      cod_comuna = 20000
    )



  # Identify key comunas
  most_growth_id   <- growth_summary$cod_comuna[which.max(growth_summary$cum_growth)]
  least_growth_id  <- growth_summary$cod_comuna[which.min(growth_summary$cum_growth)]
  mean_growth_val  <- mean(growth_summary$cum_growth, na.rm = TRUE)
  closest_mean_id  <- growth_summary$cod_comuna[which.min(abs(growth_summary$cum_growth - mean_growth_val))]

  # --- STEP 5: Create labeled versions for plotting ---
  df_most  <- df %>% filter(cod_comuna == most_growth_id)  %>% mutate(cod_comuna = 30001)
  df_least <- df %>% filter(cod_comuna == least_growth_id) %>% mutate(cod_comuna = 30002)
  df_mid   <- df %>% filter(cod_comuna == closest_mean_id) %>% mutate(cod_comuna = 30003)

  # Combine all data
  df_final <- bind_rows(df, df_mean, df_most, df_least, df_mid)

  # --- STEP 6: Plot ---
  p <- ggplot(df_final, aes(x = as.numeric(year), y = temp, group = cod_comuna)) +
    # Background lines
    geom_line(aes(color = "Other comunas"), alpha = 0.2, linewidth = 0.3, show.legend = FALSE) +

    # Highlight Mean
    geom_line(
      data = subset(df_final, cod_comuna == 20000),
      aes(color = "Mean"),
      linewidth = 1
    ) +
    # Highlight Most Growth
    geom_line(
      data = subset(df_final, cod_comuna == 30001),
      aes(color = "Highest growth"),
      linewidth = 1
    ) +
    # Highlight Least Growth
    geom_line(
      data = subset(df_final, cod_comuna == 30002),
      aes(color = "Lowest growth"),
      linewidth = 1
    ) +
    # Highlight Closest to Mean
    geom_line(
      data = subset(df_final, cod_comuna == 30003),
      aes(color = "Closest to mean"),
      linewidth = 1
    ) +

    # Manual color and legend labels
    scale_color_manual(values = c(
      "Other comunas" = "gray60",
      "Mean" = "black",
      "Highest growth" = "red",
      "Lowest growth" = "green",
      "Closest to mean" = "blue"
    )) +

    # Titles and labels
    labs(
      x = "Year",
      y = "Climate Index (baseline = 100)",
      color = "Comuna type",
      title = paste("Climate Trends by Comuna -", toupper(var_name)),
      subtitle = paste0(
        "Highlighted automatically:\n",
        "Highest growth: ", most_growth_id, " | ",
        "Lowest growth: ", least_growth_id, " | ",
        "Closest to mean: ", closest_mean_id
      )
    ) +
    theme_minimal()

  # --- STEP 7: Export data and plot ---
  ggsave(
    filename = paste0(out_path, "plot_", var_name, ".png"),
    plot = p,
    width = 8,
    height = 5,
    dpi = 300
  )

  message(paste("✅ Done:", var_name))
  return(list(data = df_final, plot = p))
}

# --- STEP 8: Run loop for all variables ---
results <- lapply(names(files), function(nm) process_climate(files[[nm]], nm))
names(results) <- names(files)



# --- Input and Output Paths ---
base_path <- "C:/Users/black/Dropbox/Sick Leave, Heat, Pollution/data/B_intermediate/"
out_path  <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/graphs/"

# --- STEP 1: Load one dataset containing all variables ---
data <- read_dta(paste0(base_path, "pollution.dta"))

# Expect structure like: cod_comuna, date, tmax, tmin, pr
data$year <- format(data$date, "%Y")

# --- Variables to process ---
vars <- c("meanMP10", "meanMP25", "meanNOX", "meanO3")

# --- Function to process and plot each variable ---
process_var <- function(df, var_name) {
  message(paste("Processing:", var_name))
  
  # --- STEP 2: Average by comuna-year for that variable ---
  df_s <- df %>%
    group_by(cod_comuna, year) %>%
    summarise(
      tempe = mean(.data[[var_name]], na.rm = TRUE),
      .groups = "drop"
    )

  # --- STEP 3: Normalize (baseline = 100) ---
  df_norm <- df_s %>%
    group_by(cod_comuna) %>%
    arrange(year, .by_group = TRUE) %>%
    mutate(
      baseline = first(tempe),
      temp = 100 * tempe / baseline
    ) %>%
    ungroup()
  # --- STEP 5: Consistent (cumulative) growth ---
  growth_summary <- df_norm %>%
    group_by(cod_comuna) %>%
    summarise(
      cum_growth = mean(temp - 100, na.rm = TRUE),
      .groups = "drop"
    )
    # --- STEP 5.1: Trim outliers (5–95 percentile) ---
  p5  <- quantile(growth_summary$cum_growth, 0.05, na.rm = TRUE)
  p95 <- quantile(growth_summary$cum_growth, 0.95, na.rm = TRUE)
  growth_summary <- growth_summary %>%
    filter(cum_growth >= p5, cum_growth <= p95)
  # Filter the main df to keep only trimmed comunas
  df_norm <- df_norm %>%
    filter(cod_comuna %in% growth_summary$cod_comuna)
  # --- STEP 4: Compute yearly mean (cod_comuna = 20000) ---
  df_mean <- df_norm %>%
    group_by(year) %>%
    summarise(
      temp = mean(temp, na.rm = TRUE),
      cod_comuna = 20000
    )



  most_growth_id   <- growth_summary$cod_comuna[which.max(growth_summary$cum_growth)]
  least_growth_id  <- growth_summary$cod_comuna[which.min(growth_summary$cum_growth)]
  mean_growth_val  <- mean(growth_summary$cum_growth, na.rm = TRUE)
  closest_mean_id  <- growth_summary$cod_comuna[which.min(abs(growth_summary$cum_growth - mean_growth_val))]

  # --- STEP 6: Create labeled versions ---
  df_most  <- df_norm %>% filter(cod_comuna == most_growth_id)  %>% mutate(cod_comuna = 30001)
  df_least <- df_norm %>% filter(cod_comuna == least_growth_id) %>% mutate(cod_comuna = 30002)
  df_mid   <- df_norm %>% filter(cod_comuna == closest_mean_id) %>% mutate(cod_comuna = 30003)
  
  df_final <- bind_rows(df_norm, df_mean, df_most, df_least, df_mid)

  # --- STEP 7: Plot ---
  p <- ggplot(df_final, aes(x = as.numeric(year), y = temp, group = cod_comuna)) +
    geom_line(aes(color = "Other comunas"), alpha = 0.2, linewidth = 0.3, show.legend = FALSE) +
    geom_line(data = subset(df_final, cod_comuna == 20000), aes(color = "Mean"), linewidth = 1) +
    geom_line(data = subset(df_final, cod_comuna == 30001), aes(color = "Highest growth"), linewidth = 1) +
    geom_line(data = subset(df_final, cod_comuna == 30002), aes(color = "Lowest growth"), linewidth = 1) +
    geom_line(data = subset(df_final, cod_comuna == 30003), aes(color = "Closest to mean"), linewidth = 1) +
    scale_color_manual(values = c(
      "Other comunas" = "gray60",
      "Mean" = "black",
      "Highest growth" = "red",
      "Lowest growth" = "green",
      "Closest to mean" = "blue"
    )) +
    labs(
      x = "Year",
      y = paste0(toupper(var_name), " Index (baseline = 100)"),
      color = "Comuna type",
      title = paste("Pollution Trends by Comuna -", toupper(var_name)),
      subtitle = paste0(
        "Highlighted automatically:\n",
        "Highest growth: ", most_growth_id, " | ",
        "Lowest growth: ", least_growth_id, " | ",
        "Closest to mean: ", closest_mean_id
      )
    ) +
    theme_minimal()

  # --- STEP 8: Export ---
  ggsave(
    filename = paste0(out_path, "plot_", var_name, ".png"),
    plot = p,
    width = 8, height = 5, dpi = 300
  )

  message(paste("✅ Done:", var_name))
  return(list(data = df_final, plot = p))
}

# --- STEP 9: Loop over variables ---
results <- lapply(vars, function(v) process_var(data, v))
names(results) <- vars

########################################################
########################################################
# Load required packages
########################################################
library(tidyverse)

########################################################
# 1. READ .TEX FILE
########################################################

tex_file <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/tables/y_sick_w.tex"
raw <- readLines(tex_file)

########################################################
# 2. IDENTIFY COEFFICIENT AND SE ROWS
########################################################

coef_rows <- raw[str_detect(raw, "^tmax\\\\_dum")]
se_rows   <- raw[str_detect(raw, "^\\s*&\\s*\\(")]

########################################################
# 3. HELPERS
########################################################

# IMPORTANT: remove \sym{...} FIRST
clean_row <- function(x) {
  x |>
    str_replace_all("\\\\sym\\{\\*+\\}", "")
}

clean_num <- function(x) {
  x |>
    str_squish() |>
    as.numeric()
}

extract_cells <- function(x) {
  str_split(x, "&")[[1]][-1] |>
    str_remove_all("\\\\") |>
    str_trim()
}

########################################################
# 4. PARSE COEFFICIENTS (ALL 4, FIXED)
########################################################

coef_df <- tibble(row = coef_rows) |>
  mutate(
    row = clean_row(row),   # <-- FIX HERE
    bin = str_extract(row, "dum\\\\_[0-9_]+") |>
      str_replace_all("\\\\_", "_"),
    vals = map(row, extract_cells)
  ) |>
  unnest_wider(vals, names_sep = "_") |>
  mutate(across(starts_with("vals"), clean_num))

########################################################
# 5. PARSE STANDARD ERRORS (ALL 4)
########################################################

se_df <- tibble(row = se_rows) |>
  mutate(
    vals = map(
      row,
      ~ str_extract_all(.x, "\\(([0-9\\.]+)\\)")[[1]] |>
        str_remove_all("[()]") |>
        as.numeric()
    )
  ) |>
  unnest_wider(vals, names_sep = "_")

########################################################
# 6. COMBINE + LONG FORMAT
########################################################

models <- c("Dummy", "Spain", "Reactive", "Anticipated")

# ---- coefficients to long ----
coef_long <- coef_df |>
  pivot_longer(
    cols = starts_with("vals"),
    names_to = "model_id",
    values_to = "estimate"
  ) |>
  mutate(
    model = models[as.integer(str_remove(model_id, "vals_"))]
  ) |>
  select(bin, model, estimate)

# ---- SEs to long ----
se_long <- coef_df |>
  select(bin) |>
  bind_cols(se_df) |>
  pivot_longer(
    cols = starts_with("vals"),
    names_to = "model_id",
    values_to = "se"
  ) |>
  mutate(
    model = models[as.integer(str_remove(model_id, "vals_"))]
  ) |>
  select(bin, model, se)


# ---- combine correctly (JOIN, not bind_cols) ----
reg_long <- coef_long |>
  left_join(se_long, by = c("bin", "model")) |>
  group_by(model) |>
  mutate(
    lower = estimate - 1.96 * se,
    upper = estimate + 1.96 * se,
    bin_index = row_number()
  ) |>
  ungroup()



########################################################
# 7. BIN LABELS (UNCHANGED)
########################################################

NEW_LABELS <- c(
  dum_9 = "< 9",
  dum_10 = "10–11",
  dum_12 = "12–13",
  dum_14 = "14–15",
  dum_16 = "16–17",
  dum_18 = "18–19",
  dum_22 = "22–23",
  dum_24 = "24–25",
  dum_26 = "26–27",
  dum_28 = "28–29",
  dum_30 = "30–31",
  dum_32 = "32–33",
  dum_34 = "34–35",
  dum_36 = "36–37",
  dum_38 = "> 38"
)

reg_long <- reg_long |>
  mutate(bin_label = recode(bin, !!!NEW_LABELS))

########################################################
# 8. PLOTTING FUNCTION
########################################################

plot_model <- function(df, subtitle_text) {
  ggplot(df, aes(
    x = fct_inorder(bin_label),
    y = estimate,
    fill = bin_index
  )) +
    geom_col(width = 0.8) +
    geom_errorbar(
      aes(ymin = lower, ymax = upper),
      width = 0.15,
      color = "black"
    ) +
    scale_fill_gradientn(
      colors = my_cols(seq(0, 1, length.out = nrow(df))),
      guide = "none"
    ) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    coord_cartesian(ylim = c(-0.1, 0.5)) +
    labs(
      x = "Bin",
      y = "Estimate",
      title = "Regression Coefficients ",
      subtitle = subtitle_text
    ) +
    theme_minimal(base_size = 14) +
    theme(
      axis.text.x = element_text(angle = 60, hjust = 1),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )
}

########################################################
# 9. GENERATE & SAVE PLOTS
########################################################
# Gradient palette (same behavior as before)
my_cols <- function(x) {
  grDevices::colorRampPalette(c("#4575b4", "#ffffbf", "#d73027"))(length(x))
}
plots <- split(reg_long, reg_long$model) |>
  map(~ plot_model(.x, unique(.x$model)))

ggsave("dummy.png",       plots$Dummy,       width = 12, height = 8, dpi = 300)
ggsave("spain.png",       plots$Spain,       width = 12, height = 8, dpi = 300)
ggsave("reactive.png",    plots$Reactive,    width = 12, height = 8, dpi = 300)
ggsave("anticipated.png", plots$Anticipated, width = 12, height = 8, dpi = 300)


########################################################
# 1. READ .TEX FILE
########################################################

tex_file <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/tables/y_sick_w_min.tex"
raw <- readLines(tex_file)

########################################################
# 2. IDENTIFY COEFFICIENT AND SE ROWS
########################################################

coef_rows <- raw[str_detect(raw, "^tmin\\\\_dum")]
se_rows   <- raw[str_detect(raw, "^\\s*&\\s*\\(")]

########################################################
# 3. HELPERS
########################################################

# IMPORTANT: remove \sym{...} FIRST
clean_row <- function(x) {
  x |>
    str_replace_all("\\\\sym\\{\\*+\\}", "")
}

clean_num <- function(x) {
  x |>
    str_squish() |>
    as.numeric()
}

extract_cells <- function(x) {
  str_split(x, "&")[[1]][-1] |>
    str_remove_all("\\\\") |>
    str_trim()
}

########################################################
# 4. PARSE COEFFICIENTS (ALL 4, FIXED)
########################################################

coef_df <- tibble(row = coef_rows) |>
  mutate(
    row = clean_row(row),   # <-- FIX HERE
    bin = str_extract(row, "dum\\\\_[0-9_]+") |>
      str_replace_all("\\\\_", "_"),
    vals = map(row, extract_cells)
  ) |>
  unnest_wider(vals, names_sep = "_") |>
  mutate(across(starts_with("vals"), clean_num))

########################################################
# 5. PARSE STANDARD ERRORS (ALL 4)
########################################################

se_df <- tibble(row = se_rows) |>
  mutate(
    vals = map(
      row,
      ~ str_extract_all(.x, "\\(([0-9\\.]+)\\)")[[1]] |>
        str_remove_all("[()]") |>
        as.numeric()
    )
  ) |>
  unnest_wider(vals, names_sep = "_")

########################################################
# 6. COMBINE + LONG FORMAT
########################################################

models <- c("Dummy", "Spain", "Reactive", "Anticipated")

# ---- coefficients to long ----
coef_long <- coef_df |>
  pivot_longer(
    cols = starts_with("vals"),
    names_to = "model_id",
    values_to = "estimate"
  ) |>
  mutate(
    model = models[as.integer(str_remove(model_id, "vals_"))]
  ) |>
  select(bin, model, estimate)

# ---- SEs to long ----
se_long <- coef_df |>
  select(bin) |>
  bind_cols(se_df) |>
  pivot_longer(
    cols = starts_with("vals"),
    names_to = "model_id",
    values_to = "se"
  ) |>
  mutate(
    model = models[as.integer(str_remove(model_id, "vals_"))]
  ) |>
  select(bin, model, se)


# ---- combine correctly (JOIN, not bind_cols) ----
reg_long <- coef_long |>
  left_join(se_long, by = c("bin", "model")) |>
  group_by(model) |>
  mutate(
    lower = estimate - 1.96 * se,
    upper = estimate + 1.96 * se,
    bin_index = row_number()
  ) |>
  ungroup()



########################################################
# 7. BIN LABELS (UNCHANGED)
########################################################

NEW_LABELS <- c(
  dum_1 = "< 0",
  dum_0 = "0–1",
  dum_2 = "2–3",
  dum_4 = "4–5",
  dum_6 = "6–7",
  dum_10 = "10–11",
  dum_12 = "12–13",
  dum_14 = "14–15",
  dum_16 = "16–17",
  dum_18 = "18–19",
  dum_20 = ">20"
)

reg_long <- reg_long |>
  mutate(bin_label = recode(bin, !!!NEW_LABELS))

########################################################
# 8. PLOTTING FUNCTION
########################################################

plot_model <- function(df, subtitle_text) {
  ggplot(df, aes(
    x = fct_inorder(bin_label),
    y = estimate,
    fill = bin_index
  )) +
    geom_col(width = 0.8) +
    geom_errorbar(
      aes(ymin = lower, ymax = upper),
      width = 0.15,
      color = "black"
    ) +
    scale_fill_gradientn(
      colors = my_cols(seq(0, 1, length.out = nrow(df))),
      guide = "none"
    ) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    coord_cartesian(ylim = c(-0.1, 0.5)) +
    labs(
      x = "Bin",
      y = "Estimate",
      title = "Regression Coefficients ",
      subtitle = subtitle_text
    ) +
    theme_minimal(base_size = 14) +
    theme(
      axis.text.x = element_text(angle = 60, hjust = 1),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )
}

########################################################
# 9. GENERATE & SAVE PLOTS
########################################################
# Gradient palette (same behavior as before)
my_cols <- function(x) {
  grDevices::colorRampPalette(c("#4575b4", "#ffffbf", "#d73027"))(length(x))
}
plots <- split(reg_long, reg_long$model) |>
  map(~ plot_model(.x, unique(.x$model)))

ggsave("dummy_m.png",       plots$Dummy,       width = 12, height = 8, dpi = 300)
ggsave("spain_m.png",       plots$Spain,       width = 12, height = 8, dpi = 300)
ggsave("reactive_m.png",    plots$Reactive,    width = 12, height = 8, dpi = 300)
ggsave("anticipated_m.png", plots$Anticipated, width = 12, height = 8, dpi = 300)

########################################################

# Load required packages
library(tidyverse)

#----------------------------------------------------------
# 1. READ & PARSE .TEX REGRESSION TABLE AUTOMATICALLY
#----------------------------------------------------------

tex_file <- "C:/Users/black/Documents/GitHub/env-shocks-and-leave-sicks/tables/y_sick0_pol_tot_dum.tex"   # ← change to your .tex path

raw <- readLines(tex_file)
#----------------------------------------------------------
# 2. EXTRACT COEFFICIENT ROWS (dum\_ pattern)
#----------------------------------------------------------

coef_rows <- raw[str_detect(raw, "dum\\\\_")]

#----------------------------------------------------------
# 3. EXTRACT STANDARD ERROR ROWS
#----------------------------------------------------------

se_rows <- raw[str_detect(raw, "\\([0-9]*\\.?[0-9]+\\)")] 

#----------------------------------------------------------
# 4. MATCH LENGTHS
#----------------------------------------------------------

n_coef <- length(coef_rows)
n_se   <- length(se_rows)

if (n_coef > n_se) {
  coef_rows <- coef_rows[1:n_se]
}

#----------------------------------------------------------
# 5. PARSE COEFFICIENT ROWS
#----------------------------------------------------------

clean_num <- function(x) {
  x |>
    str_replace_all("\\\\sym\\{\\*+\\}", "") |>
    str_squish() |>
    as.numeric()
}

coef_df <- tibble(row = coef_rows) |>
  mutate(
    # bin names; convert "dum\_9" → "dum_9"
    bin = str_extract(row, "dum\\\\_[0-9_]+") |> 
      str_replace_all("\\\\_", "_"),

    coef1 = str_match(row, "&\\s*([^&\\\\]+)")[,2] |> clean_num(),
    coef2 = str_match(row, "&[^&]+&\\s*([^\\\\]+)")[,2] |> clean_num()
  ) |>
  select(bin, coef1, coef2)

#----------------------------------------------------------
# 6. PARSE SE ROWS
#----------------------------------------------------------

se_df <- tibble(row = se_rows) |>
  mutate(
    # extract ALL numbers inside parentheses
    all_se = str_extract_all(row, "\\(([0-9\\.]+)\\)") 
  ) |>
  mutate(
    se1 = all_se |> map_dbl(~ as.numeric(str_remove_all(.x[1], "[()]"))),
    se2 = all_se |> map_dbl(~ as.numeric(str_remove_all(.x[2], "[()]")))
  ) |>
  select(se1, se2)

#----------------------------------------------------------
# 7. COMBINE + COMPUTE CI
#----------------------------------------------------------

reg_df <- bind_cols(coef_df, se_df)

reg_clean <- reg_df |>
  mutate(
    estimate = coef1,
    se = se1,
    lower = estimate - 1.96 * se,
    upper = estimate + 1.96 * se,
    bin = fct_inorder(bin),
    bin_index = row_number()
  ) |>
  select(bin, estimate, se, lower, upper, bin_index)

#----------------------------------------------------------
# 8. PLACE TO RENAME BINS
#----------------------------------------------------------
# Create a named vector:
# NEW_LABELS["old_bin_name"] = "new_label"


# Apply custom labels:
reg_clean <- reg_clean |>
  mutate(bin_label = recode(bin, !!!NEW_LABELS))

#----------------------------------------------------------
# 9. COLOR GRADIENT BASED ON BIN ORDER
#----------------------------------------------------------

my_cols <- scales::seq_gradient_pal(low = "#008080", high = "#CC0000")

#----------------------------------------------------------
# 10. BAR PLOT WITH BLACK ERROR BARS
#----------------------------------------------------------

p1 <- reg_clean |>
  ggplot(aes(x = fct_inorder(bin_label), 
             y = estimate,
             fill = bin_index)) +
  geom_col(width = 0.8) +
  geom_errorbar(
    aes(ymin = lower, ymax = upper),
    width = 0.15,
    color = "black"
  ) +
  scale_fill_gradientn(
    colors = my_cols(seq(0, 1, length.out = nrow(reg_clean))),
    guide = "none"   # <-- removes legend
  ) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_cartesian(ylim = c(-0.1, 0.5)) +
  labs(
    x = "Bin",
    y = "Estimate",
    title = "Regression Coefficients ",
    subtitle = "Max weekly temperature"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 60, hjust = 1)
  )
  p1
  
  ggsave(
  filename = "dummy_pol.png",
  plot = p1,     # or your_plot_object
  width = 12,             # inches
  height = 8,
  dpi = 300               # publication quality
)
